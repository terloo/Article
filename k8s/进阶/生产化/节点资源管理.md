# 节点资源管理

## 状态汇报
kubelet周期性的向APIServer进行汇报，并更新节点的相关健康和资源信息
- 节点基础信息：包括ip地址、操作系统、内核、运行时、kubelet、kube-proxy版本信息。保存在`status.nodeInfo`中
- 节点资源信息：包括cpu、内存、HugePage、临时存储、GPU等注册设备，以及这些资源中能分配给容器使用的部分。保存在`status.conditions`中
- 调度器在为Pod选择节点时会将机器的状态信息作为选择依据

| `status.conditions`种类 | 说明                 |
| ----------------------- | -------------------- |
| Ready                   | 节点是否健康         |
| MemoryPressure          | 节点内存是否存在压力 |
| PIDPressure             | 节点pi是否存在压力   |
| DiskPressure            | 节点磁盘是否存在压力 |
| NetworkUnavailabel      | 节点网络是否配置正确 |

## 资源预留
| 属性                      | 说明               |
| ------------------------- | ------------------ |
| status.capacity           | 节点资源总量       |
| status.capacity.ephemeral | 根分区大小         |
| status.allocatable        | 节点剩余可分配资源 |

## 防止资源耗尽的防御驱逐机制
- kubelet会在资源不够时中止一些容器进程，以空出节点资源，保证节点的稳定性
- 由kubelet发起的驱逐只停止Pod的所有容器进程，并不会直接删除Pod，以供排查错误
  - Pod的status.phase会被标记为Failed
  - status.reason会被设置为Evicted
  - status.message会记录驱逐原因

## 容器和系统资源的配置

### CPU子系统的组织结构
针对不同QoS Class的Pod，kubernetes按如下Hierarchy组织cgroup中的cpu子系统，运行时为docker。  
- `/sys/fs/cgroup/cpu`
   - `kubepods.slice`
     - `kubepods-besteffort.slice`
       - `kubepods-pod<podUID>.slice`
         - `docker-<dockerId1>.scope`
         - `docker-<dockerId2>.scope`
     - `kubepods-burstable.slice`
       - `kubepods-pod<podUID>.slice`
         - `docker-<dockerId1>.scope`
         - `docker-<dockerId2>.scope`
     - `kubepods-pod<podUID>.slice`
       - `docker-<dockerId1>.scope`
       - `docker-<dockerId2>.scope`
> Guaranteed的Pod没有外层目录

### CPU cgroups的配置
| 类型   | 参数             | Qos类型    | 值                    |
| ------ | ---------------- | ---------- | --------------------- |
| 主容器 | cpu.shares       | BestEffort | 2                     |
| 主容器 | cpu.shares       | Burstable  | requests.cpu*1024     |
| 主容器 | cpu.shares       | Guaranteed | requests.cpu*1024     |
| 主容器 | cpu.cfs_quota_us | BestEffort | -1                    |
| 主容器 | cpu.cfs_quota_us | Burstable  | limits.cpu*100        |
| 主容器 | cpu.cfs_quota_us | Guaranteed | limits.cpu*100        |
| Pod    | cpu.shares       | BestEffort | 2                     |
| Pod    | cpu.shares       | Burstable  | requests.cpu*1024之和 |
| Pod    | cpu.shares       | Guaranteed | requests.cpu*1024之和 |
| Pod    | cpu.cfs_quota_us | BestEffort | -1                    |
| Pod    | cpu.cfs_quota_us | Burstable  | limits.cpu*100之和    |
| Pod    | cpu.cfs_quota_us | Guaranteed | limits.cpu*100之和    |
> pause容器的cpu.shares均为2，cpu.cfs_quota_us均为-1

### Memory子系统的组织结构
- `/sys/fs/cgroup/memory`
   - `kubepods.slice`
     - `kubepods-besteffort.slice`
       - `kubepods-pod<podUID>.slice`
         - `docker-<dockerId1>.scope`
         - `docker-<dockerId2>.scope`
     - `kubepods-burstable.slice`
       - `kubepods-pod<podUID>.slice`
         - `docker-<dockerId1>.scope`
         - `docker-<dockerId2>.scope`
     - `kubepods-pod<podUID>.slice`
       - `docker-<dockerId1>.scope`
       - `docker-<dockerId2>.scope`

### Memory Cgroups配置
| 类型   | 参数                  | Qos类型    | 值                    |
| ------ | --------------------- | ---------- | --------------------- |
| 主容器 | memory.limit_in_bytes | BestEffort | 9223372036854771712   |
| 主容器 | memory.limit_in_bytes | Burstable  | limits.memory         |
| 主容器 | memory.limit_in_bytes | Guaranteed | limits.memory         |
| Pod    | cpu.shares            | BestEffort | 9223372036854771712   |
| Pod    | cpu.shares            | Burstable  | requests.cpu*1024之和 |
| Pod    | cpu.shares            | Guaranteed | requests.cpu*1024之和 |
> pause容器的limit_in_bytes均为9223372036854771712

## OOM Killer行为
1. 系统的OOM Killer可能为采用OOM的方式来终止某些容器进程，进行必要的内存回收操作
2. 系统根据进程的oom_score来进行优先级排序，oom_score越高，越容易被终止
3. 进程的oom_score计算公式`processMemoryUsageBytes/machineMemoryCapacityBytes * 1000 + oom_score_adj`
4. 容器进程的oom_score
   1. Guaranteed：-997
   2. BestEffort：1000
   3. Burstable：$$min(max(2, 1000-\frac{(memoryRequestesBytes\times1000)}{machineMemoryCapacityBytes}), 999)$$

# Docker卷管理
1. 在构建容器镜像时，可以在Dockerfile中通过VOLUME指令声明一个存储卷，目前k8s并未将其纳入管控范围内，不建议使用
2. 如果容器进程在可写层或emptyDir卷进行大量读写操作，就会导致磁盘IO过高，从而影响其他容器进行甚至系统进程
3. Docker和Containerd都基于CGroups v1。对于块设备，只支持Direct I/O限速，而对于Buffer I/O不具备有效支持。因此对于有特殊IO要求的容器，建议使用独立的磁盘空间

## 网络资源管理
由网络插件通过Linux Traffic Control为Pod限制带宽，可以利用社区提供的bandwidth插件进行实现
```yaml
apiVersion: v1
kind: Pod
metadata:
  annotations:
    kubernetes.io/ingress-bandwidth: 10MB
    kubernetes.io/egress-bandwidth: 10MB
```

## 进程数管理
kubelet默认不限制Pod的进程数，但可以通过启动参数`podPidLimit`开启限制，还可以由reserved参数为系统进程预留进程数
1. kubelet通过系统调用周期性地获取当前系统的PID使用量，并读取/proc/sys/kernel/pid_max，获取系统支持的PID上限
2. 如果当前的可用进程数少于设定阈值，那么kubelet将会把Node的PIDPressure标记为True，阻止Pod调度